{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Single chromosome optimization using OpenMiChroM\n",
    "\n",
    "\n",
    "## This tutorial performs optimization in the MiChroM Parameters (Second-order optimization -> Hessian inversion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The first step is to import the OpenMiChroM modules.*\n",
    "\n",
    "To install OpenMM and OpenMiChroM, follow the [instalation guide](https://open-michrom.readthedocs.io/en/latest/#).\n",
    "\n",
    "The inputs and apps used in this tutorial can be downloaded [here](https://github.com/junioreif/OpenMiChroM/tree/main/Tutorials/MiChroM_Optimization).\n",
    "\n",
    "<font color='red'>Types optimization is available starting in the OpenMichroM version 1.0.7.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenMiChroM simulation module\n",
    "from OpenMiChroM.ChromDynamics import MiChroM\n",
    "# Optimization of MiChroM parameters module\n",
    "from OpenMiChroM.Optimization import CustomMiChroMTraining\n",
    "# Analysis tools module\n",
    "from OpenMiChroM.CndbTools import cndbTools\n",
    "\n",
    "# Extra modules to load and plot .dense file \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy.optimize import curve_fit\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The second step is to have a look on the experimental Hi-C*\n",
    "\n",
    "A Hi-C file is required for the analysis and training of the MiChroM Potentials (Types and Ideal Chromosome). The file format chosen here is a matrix .txt file (we call it the dense file).\n",
    "\n",
    "For this tutorial, we will use chromosome 10 from GM12878 in 100 kb resolution. To extract it from the .hic file, we can use juicer_tools with the folowing command. Please note that the juicer_tools java file is located at the `apps` folder located at the `$HOME` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#java -jar ~/apps/juicer_tools_1.22.01.jar dump observed Balanced -d https://hicfiles.s3.amazonaws.com/hiseq/gm12878/in-situ/combined.hic 10 10 BP 100000 input/chr10_100k.dense\n",
    "# download the file in github"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command downloads the .hic from the web and extracts the chromosome 10 in .dense format to the folder \"input\".\n",
    "\n",
    "You can get more information about it at the [JuicerTools](https://github.com/aidenlab/juicer) documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the .dense file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'input/chr10_100k.dense'\n",
    "hic_file = np.loadtxt(filename)\n",
    "\n",
    "r=np.triu(hic_file, k=1) \n",
    "r[np.isnan(r)]= 0.0\n",
    "r = normalize(r, axis=1, norm='max') \n",
    "rd = np.transpose(r) \n",
    "r=r+rd + np.diag(np.ones(len(r)))\n",
    "print(\"number of beads: \", len(r))\n",
    "plt.matshow(r,norm=mpl.colors.LogNorm(vmin=0.0001, vmax=r.max()),cmap=\"Reds\")  \n",
    "plt.colorbar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Hi-C map has a resolution of 100 kb per bead, so the chromosome 10 model has a polymer chain with a total of 1356 beads."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to extract the sequence file containing the A/B compartments along the sequence by using the eigenvector decomposition. <br>\n",
    "\n",
    "Using the juicertools, you can extract the eigenvector file. The eigenvector has values both negatives and positives and here we will arbitrary set positives as B and negatives as A. <br>\n",
    "\n",
    "For more details about how it works, please take a look on this paper: https://pubs.acs.org/doi/full/10.1021/acs.jpcb.1c04174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#java -jar ~/apps/juicer_tools_1.22.01.jar eigenvector -p Balanced https://hicfiles.s3.amazonaws.com/hiseq/gm12878/in-situ/combined.hic 10 BP 100000 input/chr10_100k.eigen\n",
    "# download the file in github"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize the .eigen file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen = np.loadtxt(\"input/chr10_100k.eigen\")\n",
    "\n",
    "index = np.arange(eigen.size)\n",
    "df = pd.Series(eigen, index=index)\n",
    "\n",
    "A1_df = pd.Series(np.zeros(eigen.size), index=index) \n",
    "A1_df[df < 0] = df[df < 0]\n",
    "B1_df = pd.Series(np.zeros(eigen.size), index=index) \n",
    "B1_df[df > 0] = df[df > 0]\n",
    "\n",
    "NA_df = df.isna()\n",
    "# y = sc.signal.savgol_filter(A1,20, 2)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2,\n",
    "                         figsize=(6.4*3/2, 4.8*2/3),\n",
    "                         gridspec_kw={'height_ratios': [1, 10]})\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(hspace=0.05) # top=0.92, bottom=0.01, wspace=0.)\n",
    "\n",
    "# sequence\n",
    "A11_df = A1_df.copy()\n",
    "A11_df[A1_df<0] = 1\n",
    "B11_df = B1_df.copy()\n",
    "B11_df[B1_df>0] = 1\n",
    "\n",
    "axes[0].axis('off')\n",
    "width=1\n",
    "axes[0].bar(A11_df.index, A11_df,\n",
    "       width,\n",
    "       color=\"tab:red\")\n",
    "axes[0].bar(B11_df.index, B11_df,\n",
    "       width,\n",
    "       color=\"tab:blue\")\n",
    "\n",
    "axes[0].set_xlim([-50,eigen.size + 50])\n",
    "\n",
    "# Eigen PC1\n",
    "step=1\n",
    "axes[1].fill_between(A1_df.index[::step], A1_df[::step],  0,\n",
    "                facecolor=\"tab:red\",\n",
    "                alpha=0.8,\n",
    "                label=\"A\")\n",
    "axes[1].fill_between(B1_df.index[::step], B1_df[::step],  0,\n",
    "                facecolor=\"tab:blue\",\n",
    "                alpha=0.8,\n",
    "                label=\"B\")\n",
    "\n",
    "axes[1].set_ylim([-0.05,0.05])\n",
    "axes[1].set_xlim([-50,eigen.size + 50])\n",
    "\n",
    "axes[1].set_ylabel('Eigen values, PC1')\n",
    "axes[1].set_xlabel('Genomic distance (50 kb)')\n",
    "\n",
    "axes[1].legend(title='compartments', bbox_to_anchor=(1.,1.45), \n",
    "               frameon=False)\n",
    "\n",
    "print(\"Number of beads: A1 = \", A1_df[A1_df<0].shape[0], \n",
    "      \", B1 = \", B1_df[B1_df>0].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the .eigen, file we can create the A/B sequence file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho para o arquivo .eigen\n",
    "file_path = \"input/chr10_100k.eigen\"\n",
    "\n",
    "# Lê o arquivo .eigen\n",
    "df = pd.read_csv(file_path, sep=\"\\s+\", header=None, names=[\"value\"])\n",
    "\n",
    "# Classifica os valores em \"A1\" (se menor que 0) e \"B1\" (se maior ou igual a 0)\n",
    "df[\"classification\"] = df[\"value\"].apply(lambda x: \"A1\" if x < 0 else \"B1\")\n",
    "\n",
    "# Adiciona números sequenciais (1, 2, 3, ...)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"index\": \"line_number\"}, inplace=True)\n",
    "df[\"line_number\"] += 1  # Ajusta para começar do 1\n",
    "\n",
    "# Salva o resultado no arquivo de saída\n",
    "output_path = \"input/seq_chr10_100k.txt\"\n",
    "df[[\"line_number\", \"classification\"]].to_csv(output_path, index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "# Conta as ocorrências de \"A1\" e \"B1\" e exibe no terminal\n",
    "classification_counts = df[\"classification\"].value_counts()\n",
    "print(f\"Arquivo gerado: {output_path}\")\n",
    "print(\"Número de classificações:\")\n",
    "print(classification_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\\# Types Interaction Opmization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the homopolimer term, MiChroM energy function has two main terms: the type-to-type and Ideal Chromosome interactions. \n",
    "\n",
    "<!--![](https://pubs.acs.org/cms/10.1021/acs.jpcb.1c04174/asset/images/medium/jp1c04174_m010.gif)-->\n",
    "\n",
    "${ U }_{\\text{MiChroM} }(\\vec { r } )={ U }_{ HP }\\left( \\vec { r }  \\right) +\\sum _{\\tiny{ \\begin{matrix}  k\\ge l \\\\ k,l \\in  \\text{Types} \\end{matrix} } }{ { \\alpha }_{ kl } } \\sum _{\\tiny{ \\begin{matrix} i \\in \\{ \\text{Loci of Type k}\\}  \\\\ j \\in  \\{ \\text{Loci of Type l} \\}  \\end{matrix} }} f({ r }_{ ij }) +  \\sum _{ d=3 }^{ { d }_{ cutoff } }{ \\gamma (d)\\sum _{ i }{ f({ r }_{ i,i+d }) }  }$\n",
    "\n",
    "In this section, the types interaction terms will be minimized."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline to perform the Types Potential Optimization is the following:\n",
    "\n",
    "1. Run a long simulation using the homopolymer + customTypes potential of the `OpenMiChroM` module. \n",
    "    The first iteration can start with all parameters equal to zero or set to an initial guess.\n",
    "\n",
    "2. Get the frames from this simualtion to perform the inversion for Types.\n",
    "\n",
    "3. In the end of the inversion, new values to types interactions will be produced.\n",
    "\n",
    "4. Calcule the error/tolerance between the simulated and experimental parameters. If it is above the treshold, re-do steps 1-3 until reaching the treshold (usually 10% or 15% is enougth)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Types file is a `.txt` with a matrix labeled with the values for each interaction. In this tutorial, we are training A and B types. <br> \n",
    "\n",
    "Lets create the initial file with this format:\n",
    "<pre><code>\n",
    "A,B\n",
    "0,0\n",
    "0,0\n",
    "</pre></code>\n",
    "For this matrix, we have AA AB BA BB interactions.\n",
    "\n",
    "Save it as `lambda_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o conteúdo do arquivo\n",
    "conteudo = \"\"\"A1,B1\n",
    "0,0\n",
    "0,0\"\"\"\n",
    "\n",
    "# Nome da pasta e do arquivo\n",
    "nome_pasta = \"input\"\n",
    "nome_arquivo = \"lambda_0.txt\"\n",
    "\n",
    "# Verificar se a pasta existe, se não, criar\n",
    "if not os.path.exists(nome_pasta):\n",
    "    os.makedirs(nome_pasta)\n",
    "\n",
    "# Caminho completo para o arquivo\n",
    "caminho_arquivo = os.path.join(nome_pasta, nome_arquivo)\n",
    "\n",
    "# Escrever o conteúdo no arquivo\n",
    "with open(caminho_arquivo, \"w\") as arquivo:\n",
    "    arquivo.write(conteudo)\n",
    "\n",
    "print(f\"O arquivo {nome_arquivo} foi salvo na pasta '{nome_pasta}' com sucesso!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the required inputs, lets perform a simulation for iteration 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MiChroM initiation there are some variables to setup:\n",
    "\n",
    "**time_step=0.01** (the time step using for integration, default is 0.01)<br>\n",
    "**temperature=1** (Set the temperature of your simulation)<br>\n",
    "**name='opt_chr10_100K'** (the simulation name)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = MiChroM(name='opt_chr10_100K', temperature=1.0, timeStep=0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to setup the platform that you will use, the options are:\n",
    "\n",
    "**platform=\"OpenCL\"** (it can also be CUDA or CPU depending of your system)<br>\n",
    "**GPU=\"0\" (optional)** (if you have more than one GPU device, you can set the GPUs that you want [\"0\", \"1\",...,\"n\"])<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.setup(platform=\"CUDA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the folder name where the output will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.saveFolder('iteration_0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to setup your chromosome sequence and initial configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mychro = simulation.createRandomWalk(ChromSeq=\"input/seq_chr10_100k.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the initial structure in the `simulation` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.loadStructure(mychro, center=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to include the force field in the `simulation` object\n",
    "\n",
    "Lets separate forces in two sets:\n",
    "\n",
    "**Homopolymer Potentials**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.addFENEBonds(kFb=30.0)\n",
    "simulation.addAngles(kA=2.0)\n",
    "simulation.addRepulsiveSoftCore(eCut=4.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chromosome Potentials**\n",
    "\n",
    "In this tutorial, it is used the CustomTypes potential. <br>\n",
    "Here we need to pass a file that contains a matrix of interactions for each other different type of chromosome.\n",
    "To check that, you can look on the [OpenMiChroM](https://open-michrom.readthedocs.io/en/latest/OpenMiChroM.html#OpenMiChroM.ChromDynamics.MiChroM.addCustomTypes) documentation. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.addCustomTypes(mu=3.22, rc = 1.78, TypesTable='input/lambda_0.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: these valeus for $\\mu$ and $r_c$ were calculated for human GM12878 cells and can be changed for other species."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last potential to be added is the spherical restraint in order to collapse the initial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation.addFlatBottomHarmonic(kR=5*10**-3, nRad=8.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run a short simulation in order to get a collapsed structure.\n",
    "\n",
    "There are two variables that control the chromosomes simulation steps:\n",
    "\n",
    "**block:** The number of steps performed in each cycle.<br>\n",
    "**n_blocks:** The number of blocks that will be perfomed. <br>\n",
    "\n",
    "In this example, to perfom the collapsing we will run $1\\times10^3 \\times  10^2 = 1\\times10^5$ steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodution = 10**6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the radius of gyration of each block to observe the convergence into the collapsed state (the time required here depends on the size of your chromosome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulation.createSimulation()\n",
    "simulation.createReporters(statistics=True, traj=True, trajFormat=\"cndb\", energyComponents=False, interval=1000)\n",
    "simulation.createReporters(statistics=True, traj=True, trajFormat=\"gro\", energyComponents=False, interval=1000)\n",
    "simulation.run(nsteps=prodution, report=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some details about the output for each block performed:\n",
    "\n",
    "**bl=0** is the number of each block, in this case we set increment=False, so the number of steps is not accounted.<br>\n",
    "**pos\\[1\\]=\\[X,Y,Z\\]** the spatial position for the first bead. <br>\n",
    "**dr=1.85** show the average positions displacement in each block (in units os sigma). <br>\n",
    "**t=1000.0 ps** the time step. in this case we set increment=False, so the number of steps is not accounted.<br>\n",
    "**kin=1.48** is the kinect energy of the system.<br>\n",
    "**pot=21.60** is the potential energy of the system. <br>\n",
    "**RG=11.809** is the radius of gyration in the end of each block. <br>\n",
    "**SPS=1538** is the steps per second of each block. A way to look how fast the computations are being performed. In this case, it was executed in a MB Pro 2021 with a Apple M1 Max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the convergence of the radius of gyration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cndbTools = cndbTools()\n",
    "chr10_traj = cndbTools.load('iteration_0/opt_chr10_100K_0.cndb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = min([int(key) for key in chr10_traj.cndb.keys() if key != 'types'])\n",
    "last_frame = max([int(key) for key in chr10_traj.cndb.keys() if key != 'types'])\n",
    "chr10_xyz = cndbTools.xyz(frames=[first_frame, last_frame,1], XYZ=[0,1,2])\n",
    "chr10_RG = cndbTools.compute_RG(chr10_xyz)\n",
    "plt.plot(chr10_RG)\n",
    "plt.ylabel(r'Radius of Gyration ($\\sigma$)',fontsize=11)\n",
    "plt.xlabel(r'Simulation Frames',fontsize=11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to remove the restraint force in order to run the sampling simulation. It also adds a confinement potential with density = 0.1 (volume fraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Flat initialized in Collapse\n",
    "simulation.removeFlatBottomHarmonic()\n",
    "\n",
    "# Add a confinement potential with density=0.1 (volume fraction)\n",
    "simulation.addSphericalConfinementLJ()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the `optimization` object for this tutorial section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization = CustomMiChroMTraining(ChromSeq=\"input/seq_chr10_100k.txt\", \n",
    "                                     TypesTable='input/lambda_0.txt',\n",
    "                                     mu=3.22, rc = 1.78)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform a long simulation to feed the optimization parameters. <br>\n",
    "\n",
    "In order to get a good inversion calcultation, it is important to have around $1\\times10^5$ frames from a certain amount of different replicas. For example, $20$ replicas with $5.000$ saved frames from each. <br> \n",
    "\n",
    "This can take some time, so in this tutorial we will use just 1 replica of $5.000$ frames saved every $1.000$ steps. <br>\n",
    "\n",
    "    block = 1000\n",
    "    n_blocks = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prodution = 10**7\n",
    "simulation.run(nsteps=prodution, report=False)\n",
    "\n",
    "# feed the optimization with the last chromosome configuration\n",
    "optimization.prob_calculation_types(simulation.getPositions())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end of each replica simulation, we need to save some important values required to calculate the inversion. <br>\n",
    "\n",
    "We are saving these files using the H5 compression because it is faster to write/read. <br>\n",
    "\n",
    "**Note**: attention to this step. We have these 4 files for each replica for each iteration step. Be organized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica=\"1\"\n",
    "\n",
    "with h5py.File(simulation.folder + \"/Nframes_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"Nframes\",  data=optimization.Nframes)\n",
    "\n",
    "with h5py.File(simulation.folder + \"/Pold_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"Pold\",  data=optimization.Pold)\n",
    "\n",
    "# Specific for Types minimization\n",
    "with h5py.File(simulation.folder + \"/Pold_type_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"Pold_type\",  data=optimization.Pold_type)\n",
    "\n",
    "with h5py.File(simulation.folder + \"/PiPj_type_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"PiPj_type\",  data=optimization.PiPj_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the optimization is finished. Look inside the output folder to see these 4 files that will be used in next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o nome da pasta\n",
    "nome_pasta = \"iteration_0\"\n",
    "\n",
    "# Verificar se a pasta existe\n",
    "if os.path.exists(nome_pasta):\n",
    "    # Listar todos os arquivos na pasta\n",
    "    arquivos = [arquivo for arquivo in os.listdir(nome_pasta) if arquivo.endswith(\".h5\")]\n",
    "    \n",
    "    # Printar os arquivos encontrados\n",
    "    if arquivos:\n",
    "        print(\"Arquivos .h5 encontrados na pasta:\")\n",
    "        for arquivo in arquivos:\n",
    "            print(arquivo)\n",
    "    else:\n",
    "        print(\"Nenhum arquivo .h5 encontrado na pasta.\")\n",
    "else:\n",
    "    print(f\"A pasta '{nome_pasta}' não existe.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is the inversion. It is quite simple, just feed the optmization object with all replicas and make the inversion to get the new lambda file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion = CustomMiChroMTraining(ChromSeq=\"input/seq_chr10_100k.txt\", \n",
    "                                  TypesTable='input/lambda_0.txt',\n",
    "                                  mu=3.22, rc = 1.78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = \"iteration_0\"\n",
    "replica    = \"1\"\n",
    "\n",
    "with h5py.File(iterations + \"/Nframes_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion.Nframes += hf['Nframes'][()]\n",
    "\n",
    "with h5py.File(iterations + \"/Pold_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion.Pold += hf['Pold'][:]\n",
    "\n",
    "# For Types\n",
    "with h5py.File(iterations + \"/Pold_type_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion.Pold_type += hf['Pold_type'][:]\n",
    "\n",
    "with h5py.File(iterations + \"/PiPj_type_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion.PiPj_type += hf['PiPj_type'][:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters of all replicas, we calculate the inversion and get the new lambdas. It is calculated by using the Newton Method: <br>\n",
    "\n",
    "$\\lambda_1 = \\lambda_0 - \\delta\\times\\lambda_{actual}$\n",
    "\n",
    "$\\delta$ is the learning rate or damp, it can be adjusted in order to get values between [-1:0]. The average value of MiChroM's parameters for Human GM12878 is -0.3 when generating $1\\times10^5$ configurations among different replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4: Executar get_lambdas_IC com norm=True implicitamente\n",
    "lambdas = inversion.get_lambdas_IC(exp_map=\"input/chr10_100k.dense\", damp=3e-7)\n",
    "\n",
    "# Passo 5: Exibir resultado\n",
    "print(\"Matriz de lambdas final:\")\n",
    "print(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_exp = np.loadtxt(\"chr10_100k.dense\")\n",
    "print(dense_exp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new lambda (`lambda_1`) and other files to analyze the inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = \"0\"\n",
    "\n",
    "# Probabilities of As/Bs in the simulation and experiment\n",
    "phi_sim = inversion.calc_phi_sim_types().ravel()\n",
    "phi_exp = inversion.calc_phi_exp_types().ravel()\n",
    "\n",
    "np.savetxt('iteration_0/phi_sim_' + iteration, phi_sim)\n",
    "np.savetxt('iteration_0/phi_exp', phi_exp)\n",
    "\n",
    "plt.plot(phi_sim[phi_sim>0], 'o', label=\"simulation\")\n",
    "plt.plot(phi_exp[phi_exp>0], 'o', label=\"experiment\")\n",
    "plt.ylabel(r'Contact probability, $\\phi$')\n",
    "labels_exp = [\"AA\", \"AB\", \"BB\"]\n",
    "plt.xticks(np.arange(len(labels_exp)), labels_exp)\n",
    "plt.legend()\n",
    "\n",
    "# Save and plot the simulated Hi-C\n",
    "dense_sim = inversion.get_HiC_sim()\n",
    "np.savetxt('iteration_0/hic_sim_' + iteration + '.dense', dense_sim)\n",
    "\n",
    "dense_exp = np.loadtxt(\"input/chr10_100k.dense\")\n",
    "dense_exp[np.isnan(dense_exp)] = 0.0\n",
    "dense_exp = normalize(dense_exp, axis=1, norm='max')\n",
    "r = np.zeros(dense_sim.size).reshape(dense_sim.shape)\n",
    "r = np.triu(dense_exp, k=1) + np.tril(dense_sim, k=-1) + np.diag(np.ones(len(r)))\n",
    "\n",
    "plt.matshow(r, \n",
    "            norm=mpl.colors.LogNorm(vmin=0.0001, \n",
    "                                    vmax=dense_sim.max()), \n",
    "            cmap=\"Reds\")\n",
    "\n",
    "# Save the new lambda file\n",
    "lambdas.to_csv(\"iteration_0/lambda_1\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redo these steps using the new lambda file (`lambda_1`) as input for Types potential in the next iteration. \n",
    "\n",
    "The tolerance can be calculate using `phi_sim_1` and `phi_exp` by the equation:<br>\n",
    "\n",
    "$tolerance = \\frac{|\\phi_{sim}-\\phi_{exp}|}{\\phi_{exp}}$\n",
    "\n",
    "This is appended in to file  `tolerance_and_pearson_types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat tolerance_and_pearson_types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We included a folder named `scripts` that has some `.py` and `.slurm` files that can be used to run this optimization in parallel using slurm clusters. It is located in our github repository https://github.com/junioreif/OpenMiChroM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\\# Ideal Chromosome Interaction Opmization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the previous section protocoal, now it is time to learn how to minimize the Ideal Chromosome (IC) interaction, the last term of our hamiltonian\n",
    "\n",
    "<!--![](https://pubs.acs.org/cms/10.1021/acs.jpcb.1c04174/asset/images/medium/jp1c04174_m010.gif)-->\n",
    "\n",
    "${ U }_{\\text{MiChroM} }(\\vec { r } )={ U }_{ HP }\\left( \\vec { r }  \\right) +\\sum _{\\tiny{ \\begin{matrix}  k\\ge l \\\\ k,l \\in  \\text{Types} \\end{matrix} } }{ { \\alpha }_{ kl } } \\sum _{\\tiny{ \\begin{matrix} i \\in \\{ \\text{Loci of Type k}\\}  \\\\ j \\in  \\{ \\text{Loci of Type l} \\}  \\end{matrix} }} f({ r }_{ ij }) +  \\sum _{ d=3 }^{ { d }_{ cutoff } }{ \\gamma (d)\\sum _{ i }{ f({ r }_{ i,i+d }) }  }$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline to perform the IC minimization is similar to the previous one:\n",
    "\n",
    "1. Run a long simulation using the homopolymer + types potential + addCustomIC of the `OpenMiChroM` module. \n",
    "    The first iteration can start with all parameters equal to zero or set to an initial guess.\n",
    "\n",
    "2. Get the frames from this simualtion to perform the inversion.\n",
    "\n",
    "3. In the end of the inversion, new values to the interactions will be produced.\n",
    "\n",
    "4. Calcule the tolerance between the simulated and experimental parameters. If it is above the treshold, re-do steps 1-3 until reaching the treshold (usually 10% or 15% is enougth)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IC file is a single column `.txt` with the values for each interaction. The file lenght should the genome distance (`d`) that you want to train. In the above equation, it goes from `d = 3` to a certain cutoff that normaly would be 200 for the human chromosome. <br> \n",
    "\n",
    "Lets create the initial file with this format:\n",
    "<pre><code>\n",
    "0\n",
    "0\n",
    ".\n",
    ".\n",
    ".\n",
    "0\n",
    "</pre></code>\n",
    "\n",
    "Save it as `lambda_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm input/lambda_0_IC &> /dev/null\n",
    "for (( i=3; i<=1356; i++ )); do echo 0 >> input/lambda_IC_0; done\n",
    "wc -l input/lambda_IC_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, create the simulation that will colapse the initial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_ic = MiChroM(name='opt_ic_chr10_100K', temperature=1.0, time_step=0.01)\n",
    "\n",
    "simulation_ic.setup(platform=\"OpenCL\")\n",
    "simulation_ic.saveFolder('iteration_ic_0')\n",
    "mychro_ic = simulation_ic.createSpringSpiral(ChromSeq=\"input/seq_chr10_100k.txt\")\n",
    "simulation_ic.loadStructure(mychro_ic, center=True)\n",
    "\n",
    "# Adding Potentials section\n",
    "\n",
    "# **Homopolymer Potentials**  \n",
    "simulation_ic.addFENEBonds(kfb=30.0)\n",
    "simulation_ic.addAngles(ka=2.0)\n",
    "simulation_ic.addRepulsiveSoftCore(Ecut=4.0)\n",
    "\n",
    "# **Chromosome Potentials**\n",
    "simulation_ic.addTypetoType()\n",
    "simulation_ic.addCustomIC(IClist=\"input/lambda_IC_0\",\n",
    "                          dinit=3, dend=200) \n",
    "\n",
    "# The restriction term for colapsing the beads\n",
    "simulation_ic.addFlatBottomHarmonic(kr=5*10**-3, n_rad=8.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the simulation to colapse the initial structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block    = 1000\n",
    "n_blocks = 200\n",
    "\n",
    "rg_ic = []\n",
    "\n",
    "for _ in range(n_blocks):\n",
    "    simulation_ic.runSimBlock(block, increment=False)\n",
    "    rg_ic.append(simulation_ic.chromRG())\n",
    "\n",
    "#save a collapsed structure in pdb format for inspection\n",
    "simulation_ic.saveStructure(mode = 'pdb')\n",
    "\n",
    "plt.plot(rg_ic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to remove the flat bottom constraint and include the spherical confinement mimicking the nuclear density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Flat initialized in Collapse\n",
    "simulation_ic.removeFlatBottomHarmonic()\n",
    "\n",
    "# Add a confinement potential with density=0.1 (volume fraction)\n",
    "simulation_ic.addSphericalConfinementLJ()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create the IC optimization object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_ic = CustomMiChroMTraining(ChromSeq=\"input/seq_chr10_100k.txt\", \n",
    "                                        TypesTable='input/lambda_0',\n",
    "                                        IClist=\"input/lambda_IC_0\",\n",
    "                                        dinit=3, dend=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to perform a long simulation to feed the optimization parameters. <br>\n",
    "\n",
    "In order to get a good inversion calcultation, it is important to have around $1\\times10^5$ frames from a certain amount of different replicas. For example, $20$ replicas with $5.000$ saved frames from each. <br> \n",
    "\n",
    "This can take some time, so in this tutorial we will use just 1 replica. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block    = 1000\n",
    "n_blocks = 5000\n",
    "\n",
    "for _ in range(n_blocks):\n",
    "    # perform 1 block of simulation\n",
    "    simulation_ic.runSimBlock(block, increment=True)\n",
    "    \n",
    "    # feed the optimization with the last chromosome configuration\n",
    "    optimization_ic.prob_calculation_IC(simulation_ic.getPositions())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to save the important files required for the inversion. <br>\n",
    "\n",
    "These files are prefered to be saved using the H5 compression. <br>\n",
    "\n",
    "**Note**: attention to this step. We have these 4 files for each replica for each iteration step. Be organized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica=\"1\"\n",
    "\n",
    "with h5py.File(simulation_ic.folder + \"/Nframes_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"Nframes\",  data=optimization_ic.Nframes)\n",
    "\n",
    "with h5py.File(simulation_ic.folder + \"/Pold_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"Pold\",  data=optimization_ic.Pold)\n",
    "\n",
    "# Specific for IC minimization\n",
    "with h5py.File(simulation_ic.folder + \"/PiPj_IC_\" + replica + \".h5\", 'w') as hf:\n",
    "    hf.create_dataset(\"PiPj_IC\",  data=optimization_ic.PiPj_IC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls iteration_ic_0/*.h5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part is the inversion. We need to feed the optmization object with all replicas and make the inversion to get the new lambda file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion_ic = CustomMiChroMTraining(ChromSeq=\"input/seq_chr10_100k.txt\",\n",
    "                                     TypesTable='input/lambda_0',\n",
    "                                     IClist=\"input/lambda_IC_0\",    \n",
    "                                     dinit=3, dend=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = \"iteration_ic_0\"\n",
    "replica    = \"1\"\n",
    "\n",
    "with h5py.File(iterations + \"/Nframes_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion_ic.Nframes += hf['Nframes'][()]\n",
    "\n",
    "with h5py.File(iterations + \"/Pold_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion_ic.Pold += hf['Pold'][:]\n",
    "\n",
    "# For IC\n",
    "with h5py.File(iterations + \"/PiPj_IC_\" + replica + \".h5\", 'r') as hf:\n",
    "    inversion_ic.PiPj_IC += hf['PiPj_IC'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters of all replicas, we calculate the inversion and get the new lambdas. It is calculated by using the Newton Method: <br>\n",
    "\n",
    "$\\lambda_1 = \\lambda_0 - \\delta\\times\\lambda_{actual}$\n",
    "\n",
    "$\\delta$ is the learning rate or damp, it can be adjusted in order to get values between [-1:0]. The average value of MiChroM's parameters for Human GM12878 is -0.3 when generating $1\\times10^5$ configurations among different replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_ic = inversion_ic.get_lambdas_IC(exp_map=\"input/chr10_100k.dense\",\n",
    "                                         damp=5e-4)\n",
    "\n",
    "lambdas_ic.size, lambdas_ic[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new lambda (`lambda_1_ic`) and other files to analyze the inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = \"0\"\n",
    "\n",
    "# Probabilities of As/Bs in the simulation and experiment\n",
    "phi_sim = inversion_ic.calc_phi_sim_IC()\n",
    "phi_exp = inversion_ic.calc_phi_exp_IC()\n",
    "\n",
    "np.savetxt('iteration_ic_0/phi_sim_' + iteration, phi_sim)\n",
    "np.savetxt('iteration_ic_0/phi_exp', phi_exp)\n",
    "\n",
    "plt.plot(phi_sim, label=\"simulation\")\n",
    "plt.plot(phi_exp, label=\"experiment\")\n",
    "plt.ylabel(r'Contact probability, $\\phi$')\n",
    "plt.xlabel(r'Genomic distance, $d$')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "# Save and plot the simulated Hi-C\n",
    "dense_sim = inversion_ic.get_HiC_sim()\n",
    "np.savetxt('iteration_ic_0/hic_sim_' + iteration + '.dense', dense_sim)\n",
    "\n",
    "dense_exp = np.loadtxt(filename)\n",
    "dense_exp[np.isnan(dense_exp)] = 0.0\n",
    "dense_exp = normalize(dense_exp, axis=1, norm='max')\n",
    "r = np.zeros(dense_sim.size).reshape(dense_sim.shape)\n",
    "r = np.triu(dense_exp, k=1) + np.tril(dense_sim, k=-1) + np.diag(np.ones(len(r)))\n",
    "\n",
    "plt.matshow(r, \n",
    "            norm=mpl.colors.LogNorm(vmin=0.0001, \n",
    "                                    vmax=dense_sim.max()), \n",
    "            cmap=\"Reds\")\n",
    "\n",
    "# Save the new lambda file\n",
    "np.savetxt(\"iteration_ic_0/lambda_1\", lambdas_ic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated interaction terms (`lambdas_1` data) can be used to fit a model in order to run production simulations with longer cutoffs in the IC energy term. The resulting model is used in the `addCustomIC` method of the `OpenMiChroM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective1(x, a, b, c):\n",
    "\treturn -a / np.log(x) - b / x**2 - c / x\n",
    "\n",
    "y = lambdas_ic\n",
    "x = np.arange(3, lambdas_ic.size + 3)\n",
    "plt.scatter(x, y, label='simulation')\n",
    "\n",
    "# curve fit\n",
    "popt, pcov = curve_fit(objective1, x, y)\n",
    "a, b, c = popt\n",
    "standard_dev = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# IC generated model \n",
    "print(popt, standard_dev)\n",
    "\n",
    "# plot the fit\n",
    "x_fit = x\n",
    "y_fit = objective1(x_fit, a, b, c)\n",
    "\n",
    "plt.plot(x_fit, y_fit, label='fitting', \n",
    "\t \t color='#ff7f0e')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice job! You have completed the optimization tutorial of the MiChroM energy terms. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
